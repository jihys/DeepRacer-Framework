{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed DeepRacer RL training with SageMaker and RoboMaker\n",
    "\n",
    "---\n",
    "## Introduction\n",
    "\n",
    "\n",
    "In this notebook, we will train a fully autonomous 1/18th scale race car using reinforcement learning using Amazon SageMaker RL and AWS RoboMaker's 3D driving simulator. [AWS RoboMaker](https://console.aws.amazon.com/robomaker/home#welcome) is a service that makes it easy for developers to develop, test, and deploy robotics applications.  \n",
    "\n",
    "This notebook provides a jailbreak experience of [AWS DeepRacer](https://console.aws.amazon.com/deepracer/home#welcome), giving us more control over the training/simulation process and RL algorithm tuning.\n",
    "\n",
    "![Training in Action](./deepracer-reinvent-track.jpg)\n",
    "\n",
    "\n",
    "---\n",
    "## How it works?  \n",
    "\n",
    "![How training works](./training.png)\n",
    "\n",
    "The reinforcement learning agent (i.e. our autonomous car) learns to drive by interacting with its environment, e.g., the track, by taking an action in a given state to maximize the expected reward. The agent learns the optimal plan of actions in training by trial-and-error through repeated episodes.  \n",
    "  \n",
    "The figure above shows an example of distributed RL training across SageMaker and two RoboMaker simulation envrionments that perform the **rollouts** - execute a fixed number of episodes using the current model or policy. The rollouts collect agent experiences (state-transition tuples) and share this data with SageMaker for training. SageMaker updates the model policy which is then used to execute the next sequence of rollouts. This training loop continues until the model converges, i.e. the car learns to drive and stops going off-track. More formally, we can define the problem in terms of the following:  \n",
    "\n",
    "1. **Objective**: Learn to drive autonomously by staying close to the center of the track.\n",
    "2. **Environment**: A 3D driving simulator hosted on AWS RoboMaker.\n",
    "3. **State**: The driving POV image captured by the car's head camera, as shown in the illustration above.\n",
    "4. **Action**: Six discrete steering wheel positions at different angles (configurable)\n",
    "5. **Reward**: Positive reward for staying close to the center line; High penalty for going off-track. This is configurable and can be made more complex (for e.g. steering penalty can be added)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we'll import the Python libraries we need, set up the environment with a few prerequisites for permissions and configurations.\n",
    "\n",
    "You can run this notebook from your local machine or from a SageMaker notebook instance. In both of these scenarios, you can run the following to launch a training job on SageMaker and a simulation job on RoboMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.DeepRacerEngine import DeepRacerEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: Single Model Run and Evaluation\n",
    "\n",
    "For this scenario, we are going to run a single model, over a chosen track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Parameters\n",
    "There are two set of parameters we can configure:\n",
    " - The simulation parameters\n",
    " - The model hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View Default Simulation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Estimator Pamrs\u001b[39;49;00m\r\n",
      "entry_point = \u001b[33m\"\u001b[39;49;00m\u001b[33mtraining_worker.py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "source_dir = \u001b[33m'\u001b[39;49;00m\u001b[33msrc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m#Training Params\u001b[39;49;00m\r\n",
      "default_instance_type = \u001b[33m\"\u001b[39;49;00m\u001b[33mml.c4.2xlarge\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[37m#For GPU use 'ml.p3.2xlarge'\u001b[39;49;00m\r\n",
      "default_instance_pool = \u001b[34m1\u001b[39;49;00m\r\n",
      "default_job_duration = \u001b[34m3600\u001b[39;49;00m\r\n",
      "default_hyperparam_preset = \u001b[33m'\u001b[39;49;00m\u001b[33msrc/markov/presets/preset_hyperparams.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "tmp_hyperparam_preset = \u001b[33m'\u001b[39;49;00m\u001b[33msrc/markov/presets/preset_hyperparams_tmp.py\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m#Track Details:\u001b[39;49;00m\r\n",
      "default_track_name = \u001b[33m'\u001b[39;49;00m\u001b[33mreinvent_base\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "track_name = [\u001b[33m'\u001b[39;49;00m\u001b[33mreinvent_base\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mreinvent_carpet\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mreinvent_concrete\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mreinvent_wood\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mAWS_track\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "              \u001b[33m'\u001b[39;49;00m\u001b[33mBowtie_track\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mOval_track\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,  \u001b[33m'\u001b[39;49;00m\u001b[33mStraight_track\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "\r\n",
      "\u001b[37m# Evaluation Trials\u001b[39;49;00m\r\n",
      "evaluation_trials = \u001b[34m5\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m## Policy and Model Meta Data\u001b[39;49;00m\r\n",
      "envir_file_local = \u001b[33m'\u001b[39;49;00m\u001b[33msrc/markov/environments/deepracer_racetrack_env.py\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "reward_file_local = \u001b[33m'\u001b[39;49;00m\u001b[33msrc/markov/rewards/complex_reward.py\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "model_meta_file_local = \u001b[33m'\u001b[39;49;00m\u001b[33msrc/markov/actions/model_metadata_10_state.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "presets_file_local = \u001b[33m'\u001b[39;49;00m\u001b[33msrc/markov/presets/preset_attention_layer.py\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize common/constant.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View Default Hypterparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \u001b[34;01m\"learning_rate\"\u001b[39;49;00m: \u001b[34m0.0003\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"batch_size\"\u001b[39;49;00m : \u001b[34m64\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"optimizer_epsilon\"\u001b[39;49;00m : \u001b[34m0.00001\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"adam_optimizer_beta2\"\u001b[39;49;00m : \u001b[34m0.999\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"clip_likelihood_ratio_using_epsilon\"\u001b[39;49;00m : \u001b[34m0.2\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"beta_entropy\"\u001b[39;49;00m : \u001b[34m0.01\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"gae_lambda\"\u001b[39;49;00m : \u001b[34m0.95\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"discount\"\u001b[39;49;00m : \u001b[34m0.999\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"optimization_epochs\"\u001b[39;49;00m : \u001b[34m10\u001b[39;49;00m\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/markov/presets/preset_hyperparams.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we can set the params we want to use for our model runs\n",
    "params = {\n",
    "    'job_name': 'dr-test-abc',\n",
    "    'track_name':'reinvent_base',\n",
    "    'job_duration': 3600,\n",
    "    'batch_size':128,\n",
    "    'evaluation_trials':5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate the DeepRacerEngine class, and provide the params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Deep Racer Engine Backend***\n"
     ]
    }
   ],
   "source": [
    "deepRacer = DeepRacerEngine(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Simulation Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************\n",
      "PERFORMING ALL DOCKER, VPC, AND ROUTING TABLE WORK....\n",
      "Using s3 bucket sagemaker-us-east-1-170991494985\n",
      "Model checkpoints and other metadata will be stored at: \n",
      "s3://sagemaker-us-east-1-170991494985/dr-test-abc-sagemaker-191224-102629\n",
      "Using Sagemaker IAM role arn: \n",
      "arn:aws:iam::170991494985:role/service-role/AmazonSageMaker-ExecutionRole-20191119T175598\n",
      "Copying files from your notebook to existing sagemaker container\n",
      "docker images sagemaker-docker-cpu | sed -n 2,2p\n",
      "Sagemaker docker id : 595fc7815164\n",
      "docker run -d -t 595fc7815164\n",
      "docker exec -d 24179134236c6976d0caded3d219a24d7fca767de07045a963c1233aa04c55df rm -rf /opt/amazon/markov\n",
      "docker cp ./src/markov 24179134236c6976d0caded3d219a24d7fca767de07045a963c1233aa04c55df:/opt/amazon/markov\n",
      "============ Copied Markov scripts to sagemaker docker ============ \n",
      " \n",
      "docker ps -l|sed -n 2,2p\n",
      "docker commit 24179134236c sagemaker-docker-cpu\n",
      "============ Commited all the changes to docker ============ \n",
      " \n",
      "Using the DeepRacer VPC stacks. This will be created if you run one training job from console.\n",
      "Using VPC: vpc-03f34e1d52556c4a0\n",
      "Using security group: ['sg-0b5a135c6d9dd4fe5']\n",
      "Using subnets: ['subnet-0c235b185de857b58', 'subnet-0bf0a2d87e239724f', 'subnet-098b2d42e516ddfa8', 'subnet-0eea622dd1a4d097c', 'subnet-0a0334c7a770c1b92', 'subnet-03e4c144f51d5211d']\n",
      "Creating Routing Tables\n",
      "Trying to attach S3 endpoints to the following route tables: ['rtb-0529a9c0f38db716c', 'rtb-0968d4b5d747e3261']\n",
      "S3 endpoint already exists.\n",
      "dr-test-abc-sagemaker-191224-102629\n",
      "Cleaning Up Tmp HyperParam file\n"
     ]
    },
    {
     "ename": "ResourceLimitExceeded",
     "evalue": "An error occurred (ResourceLimitExceeded) when calling the CreateTrainingJob operation: The account-level service limit 'ml.c4.2xlarge for training job usage' is 4 Instances, with current utilization of 4 Instances and a request delta of 1 Instances. Please contact AWS support to request an increase for this limit.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceLimitExceeded\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9b2974a9ed77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeepRacer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training_testing_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SageMaker/DeepRacer-Jupyter/src/core/DeepRacerEngine.py\u001b[0m in \u001b[0;36mstart_training_testing_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_kinesis_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/DeepRacer-Jupyter/src/core/DeepRacerEngine.py\u001b[0m in \u001b[0;36mconfigure_estimator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m                                      )\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training job: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mtrain_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"enable_sagemaker_metrics\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_sagemaker_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image, algorithm_arn, encrypt_inter_container_traffic, train_use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     def process(\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceLimitExceeded\u001b[0m: An error occurred (ResourceLimitExceeded) when calling the CreateTrainingJob operation: The account-level service limit 'ml.c4.2xlarge for training job usage' is 4 Instances, with current utilization of 4 Instances and a request delta of 1 Instances. Please contact AWS support to request an increase for this limit."
     ]
    }
   ],
   "source": [
    "deepRacer.start_training_testing_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create local folder tmp/dr-test-abc-2019-12-24-05-51-39-591\n"
     ]
    }
   ],
   "source": [
    "deepRacer.plot_training_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Evaluation Proces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepRacer.start_evaluation_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Evaluation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepRacer.plot_evaluation_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: Multi-Model Training with different HyperParameters and Evaluation\n",
    "\n",
    "For this scenario, we are going to train multiple models, with different hyperparameters, and view the training and evaluation in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Generation\n",
    "\n",
    "In this example we're going to generate some changes to the hyperparameters. Typically when conducting experiments with varible chances, only one variable is adjusted at a time, in order to allow for measurable changes (controlled experiment). If multiple variables are changed, then it is difficult to determine the impact to the hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 128, 256, 512]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'job_name': 'a-batchsize-64',\n",
       "  'track_name': 'reinvent_base',\n",
       "  'job_duration': 3600,\n",
       "  'batch_size': 64,\n",
       "  'evaluation_trials': 5},\n",
       " {'job_name': 'a-batchsize-128',\n",
       "  'track_name': 'reinvent_base',\n",
       "  'job_duration': 3600,\n",
       "  'batch_size': 128,\n",
       "  'evaluation_trials': 5},\n",
       " {'job_name': 'a-batchsize-256',\n",
       "  'track_name': 'reinvent_base',\n",
       "  'job_duration': 3600,\n",
       "  'batch_size': 256,\n",
       "  'evaluation_trials': 5},\n",
       " {'job_name': 'a-batchsize-512',\n",
       "  'track_name': 'reinvent_base',\n",
       "  'job_duration': 3600,\n",
       "  'batch_size': 512,\n",
       "  'evaluation_trials': 5}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def param_gen_batch_sizes(self, min_batch = 64, max_batch = 512, job_name_prefix= None):\n",
    "    \n",
    "    if job_name_prefix:\n",
    "        batches = []\n",
    "        btch = min_batch \n",
    "        while btch <= max_batch:\n",
    "            batches.append(btch)\n",
    "            btch *= 2\n",
    "        print(batches)\n",
    "\n",
    "        model_params = []\n",
    "        job_name = job_name_prefix+'-batchsize-'\n",
    "        for batch_size in batches:\n",
    "\n",
    "            params = {\n",
    "            'job_name': job_name+'{}'.format(batch_size),\n",
    "            'track_name':'reinvent_base',\n",
    "            'job_duration': 3600,\n",
    "            'batch_size':batch_size,\n",
    "            'evaluation_trials':5\n",
    "            }\n",
    "            model_params.append(params)\n",
    "        return model_params\n",
    "    \n",
    "param_gen_batch_sizes(None, job_name_prefix='a' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_multi_model_simulations(self):\n",
    "    \n",
    "    drs = {}\n",
    "    for param in params:\n",
    "        \n",
    "        #let's create a DeepRacerEngine instance and kick things off\n",
    "        dr = DeepRacerEngine(param)\n",
    "        drs[param['job_name']] = dr\n",
    "        dr.start_training_testing_process()\n",
    "        \n",
    "    return drs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multi_model_runs_output(self, drs):\n",
    "    \n",
    "        #create root for testing\n",
    "        self.tmp_root = 'tmp/'\n",
    "        os.system(\"mkdir {}\".format(self.tmp_root))\n",
    "    \n",
    "        job_names = []\n",
    "        tmp_dirs = []\n",
    "        for k,dr in drs.items():\n",
    "            dr.tmp_dir = \"tmp/{}\".format(dr.job_name)\n",
    "            os.system(\"mkdir {}\".format(dr.tmp_dir))\n",
    "            print(\"Create local folder {}\".format(dr.tmp_dir))\n",
    "            \n",
    "        \n",
    "            dr.training_metrics_file = \"training_metrics.json\"\n",
    "            dr.training_metrics_path = \"{}/{}\".format(dr.s3_prefix, dr.training_metrics_file)\n",
    "            \n",
    "\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
    "#         ax = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "        x_axis = 'episode'\n",
    "        y_axis = 'reward_score'\n",
    "        ytwo_axis = 'completion_percentage'\n",
    "        loops = self.job_duration_in_seconds\n",
    "\n",
    "        with HiddenPrints():\n",
    "        \n",
    "            for i in range(loops):\n",
    "                xs = {}\n",
    "                ys = {}\n",
    "                y2s = {}\n",
    "                for k,dr in drs.items():\n",
    "                    \n",
    "                    wait_for_s3_object(dr.s3_bucket, dr.training_metrics_path, dr.tmp_dir)\n",
    "\n",
    "                    json_file = \"{}/{}\".format(dr.tmp_dir, dr.training_metrics_file)\n",
    "                    with open(json_file) as fp:\n",
    "                        data = json.load(fp)\n",
    "                        data = pd.DataFrame(data['metrics'])                \n",
    "                        x = data[x_axis].values\n",
    "                        y = data[y_axis].values\n",
    "                        y2 = data[ytwo_axis].values\n",
    "                        xs[k] = x\n",
    "                        ys[k] = y\n",
    "                        y2s[k] = y2\n",
    "                        \n",
    "                #now plot them all together\n",
    "                for k,x in xs.items():\n",
    "                    ax[0].title.set_text('Reward / Episode @ {} Seconds.'.format(i))\n",
    "                    ax[0].plot(x, ys[k], label=k)\n",
    "                    ax[1].title.set_text('Track Completion / Episode @ {} Seconds.'.format(i))\n",
    "                    ax[1].plot(x, y2s[k], label=k)\n",
    "                    \n",
    "                fig.tight_layout()\n",
    "                display(fig)\n",
    "                clear_output(wait=True)\n",
    "                plt.pause(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
