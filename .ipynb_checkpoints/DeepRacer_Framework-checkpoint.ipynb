{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed DeepRacer RL training with SageMaker and RoboMaker\n",
    "\n",
    "---\n",
    "## Introduction\n",
    "\n",
    "\n",
    "In this notebook, we will train a fully autonomous 1/18th scale race car using reinforcement learning using Amazon SageMaker RL and AWS RoboMaker's 3D driving simulator. [AWS RoboMaker](https://console.aws.amazon.com/robomaker/home#welcome) is a service that makes it easy for developers to develop, test, and deploy robotics applications.  \n",
    "\n",
    "This notebook provides a jailbreak experience of [AWS DeepRacer](https://console.aws.amazon.com/deepracer/home#welcome), giving us more control over the training/simulation process and RL algorithm tuning.\n",
    "\n",
    "![Training in Action](./deepracer-reinvent-track.jpg)\n",
    "\n",
    "\n",
    "---\n",
    "## How it works?  \n",
    "\n",
    "![How training works](./training.png)\n",
    "\n",
    "The reinforcement learning agent (i.e. our autonomous car) learns to drive by interacting with its environment, e.g., the track, by taking an action in a given state to maximize the expected reward. The agent learns the optimal plan of actions in training by trial-and-error through repeated episodes.  \n",
    "  \n",
    "The figure above shows an example of distributed RL training across SageMaker and two RoboMaker simulation envrionments that perform the **rollouts** - execute a fixed number of episodes using the current model or policy. The rollouts collect agent experiences (state-transition tuples) and share this data with SageMaker for training. SageMaker updates the model policy which is then used to execute the next sequence of rollouts. This training loop continues until the model converges, i.e. the car learns to drive and stops going off-track. More formally, we can define the problem in terms of the following:  \n",
    "\n",
    "1. **Objective**: Learn to drive autonomously by staying close to the center of the track.\n",
    "2. **Environment**: A 3D driving simulator hosted on AWS RoboMaker.\n",
    "3. **State**: The driving POV image captured by the car's head camera, as shown in the illustration above.\n",
    "4. **Action**: Six discrete steering wheel positions at different angles (configurable)\n",
    "5. **Reward**: Positive reward for staying close to the center line; High penalty for going off-track. This is configurable and can be made more complex (for e.g. steering penalty can be added)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we'll import the Python libraries we need, set up the environment with a few prerequisites for permissions and configurations.\n",
    "\n",
    "You can run this notebook from your local machine or from a SageMaker notebook instance. In both of these scenarios, you can run the following to launch a training job on SageMaker and a simulation job on RoboMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.DeepRacerEngine import DeepRacerEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: Single Model Run and Evaluation\n",
    "\n",
    "For this scenario, we are going to run a single model, over a chosen track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Parameters\n",
    "There are two set of parameters we can configure:\n",
    " - The simulation parameters\n",
    " - The model hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View Default Simulation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Estimator Pamrs\u001b[39;49;00m\r\n",
      "entry_point = \u001b[33m\"\u001b[39;49;00m\u001b[33mtraining_worker.py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "source_dir = \u001b[33m'\u001b[39;49;00m\u001b[33msrc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m#Training Params\u001b[39;49;00m\r\n",
      "default_instance_type = \u001b[33m\"\u001b[39;49;00m\u001b[33mml.c4.2xlarge\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[37m#For GPU use 'ml.p3.2xlarge'\u001b[39;49;00m\r\n",
      "default_instance_pool = \u001b[34m1\u001b[39;49;00m\r\n",
      "default_job_duration = \u001b[34m3600\u001b[39;49;00m\r\n",
      "default_hyperparam_preset = \u001b[33m'\u001b[39;49;00m\u001b[33msrc/markov/presets/preset_hyperparams.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "tmp_hyperparam_preset = \u001b[33m'\u001b[39;49;00m\u001b[33msrc/markov/presets/preset_hyperparams_tmp.py\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m#Track Details:\u001b[39;49;00m\r\n",
      "default_track_name = \u001b[33m'\u001b[39;49;00m\u001b[33mreinvent_base\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "track_name = [\u001b[33m'\u001b[39;49;00m\u001b[33mreinvent_base\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mreinvent_carpet\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mreinvent_concrete\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mreinvent_wood\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mAWS_track\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "              \u001b[33m'\u001b[39;49;00m\u001b[33mBowtie_track\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mOval_track\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,  \u001b[33m'\u001b[39;49;00m\u001b[33mStraight_track\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "\r\n",
      "\u001b[37m# Evaluation Trials\u001b[39;49;00m\r\n",
      "evaluation_trials = \u001b[34m5\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m## Policy and Model Meta Data\u001b[39;49;00m\r\n",
      "envir_file_local = \u001b[33m'\u001b[39;49;00m\u001b[33msrc/markov/environments/deepracer_racetrack_env.py\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "reward_file_local = \u001b[33m'\u001b[39;49;00m\u001b[33msrc/markov/rewards/complex_reward.py\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "model_meta_file_local = \u001b[33m'\u001b[39;49;00m\u001b[33msrc/markov/actions/model_metadata_10_state.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "presets_file_local = \u001b[33m'\u001b[39;49;00m\u001b[33msrc/markov/presets/preset_attention_layer.py\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize common/constant.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View Default Hypterparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \u001b[34;01m\"learning_rate\"\u001b[39;49;00m: \u001b[34m0.0003\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"batch_size\"\u001b[39;49;00m : \u001b[34m64\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"optimizer_epsilon\"\u001b[39;49;00m : \u001b[34m0.00001\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"adam_optimizer_beta2\"\u001b[39;49;00m : \u001b[34m0.999\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"clip_likelihood_ratio_using_epsilon\"\u001b[39;49;00m : \u001b[34m0.2\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"beta_entropy\"\u001b[39;49;00m : \u001b[34m0.01\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"gae_lambda\"\u001b[39;49;00m : \u001b[34m0.95\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"discount\"\u001b[39;49;00m : \u001b[34m0.999\u001b[39;49;00m,\r\n",
      "    \u001b[34;01m\"optimization_epochs\"\u001b[39;49;00m : \u001b[34m10\u001b[39;49;00m\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/markov/presets/preset_hyperparams.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we can set the params we want to use for our model runs\n",
    "params = {\n",
    "    'job_name': 'dr-test-abc',\n",
    "    'track_name':'reinvent_base',\n",
    "    'job_duration': 3600,\n",
    "    'batch_size':128,\n",
    "    'evaluation_trials':5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate the DeepRacerEngine class, and provide the params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Deep Racer Engine Backend***\n"
     ]
    }
   ],
   "source": [
    "deepRacer = DeepRacerEngine(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Simulation Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "deepRacer.start_training_testing_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create local folder tmp/dr-test-abc-2019-12-24-05-51-39-591\n"
     ]
    }
   ],
   "source": [
    "deepRacer.plot_training_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Evaluation Proces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepRacer.start_evaluation_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Evaluation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepRacer.plot_evaluation_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: Multi-Model Training with different HyperParameters and Evaluation\n",
    "\n",
    "For this scenario, we are going to train multiple models, with different hyperparameters, and view the training and evaluation in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Generation\n",
    "\n",
    "In this example we're going to generate some changes to the hyperparameters. Typically when conducting experiments with varible chances, only one variable is adjusted at a time, in order to allow for measurable changes (controlled experiment). If multiple variables are changed, then it is difficult to determine the impact to the hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_gen_batch_sizes(self, min_batch = 64, max_batch = 512, job_name_prefix):\n",
    "    \n",
    "    batches = []\n",
    "    btch = min_batch \n",
    "    while btch <= max_batch:\n",
    "        batches.append(btch)\n",
    "        btch *= 2\n",
    "    print(batches)\n",
    "    \n",
    "    model_params = []\n",
    "    job_name = job_name_prefix+'-batchsize-'\n",
    "    for batch_size in batches:\n",
    "        \n",
    "        params = {\n",
    "        'job_name': job_name+'{}'.format(batch_size),\n",
    "        'track_name':'reinvent_base',\n",
    "        'job_duration': 3600,\n",
    "        'batch_size':batch_size,\n",
    "        'evaluation_trials':5\n",
    "        }\n",
    "    model_params.append(params)\n",
    "    \n",
    "param_gen_batch_sizes(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
